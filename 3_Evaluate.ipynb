{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "from preprocess import get_allpaths, preprocess\n",
    "from utils      import load_config, load_logger, load_parallel_pool, \\\n",
    "                       generateOutputCQTList, pitch_shift_CQT, get_querytoref\n",
    "from search     import calculateMRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirlab/miniconda3/lib/python3.6/site-packages/ipyparallel/client/client.py:458: RuntimeWarning: \n",
      "            Controller appears to be listening on localhost, but not on this machine.\n",
      "            If this is true, you should specify Client(...,sshserver='you@mirlab')\n",
      "            or instruct your controller to listen on an external IP.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "logger = load_logger()\n",
    "c      = load_parallel_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = 'taylorswift'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 459, 121)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    import tensorflow as tf\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.models import Sequential, Model\n",
    "    from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
    "    from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "    from keras.layers import Input, Concatenate, Layer\n",
    "    from keras.layers.advanced_activations import ELU\n",
    "    from keras.applications import vgg19\n",
    "    from keras.utils import plot_model\n",
    "    from keras.optimizers import RMSprop, Adam\n",
    "    from keras import backend as K\n",
    "    from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "    \n",
    "    K.set_image_data_format('channels_first')\n",
    "    width = 76\n",
    "    height = 121\n",
    "    n_channel = 1\n",
    "    \n",
    "    image_a    = Input(shape=(n_channel, width, height), name='image_1')\n",
    "    image_b    = Input(shape=(n_channel, width, height), name='image_2')\n",
    "    similarity = Input(shape=(1,), name=\"similarity\")\n",
    "    weight     = Input(shape=(1,), name=\"weight\")\n",
    "    \n",
    "    in_layer = Input(shape=(n_channel, width, height))\n",
    "    x = Convolution2D(64, (7,7))(in_layer)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D(strides=(2,2))(x)\n",
    "\n",
    "    x = Convolution2D(192, (3,3))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D(strides=(2,2))(x)\n",
    "\n",
    "    x = Convolution2D(128, (1,1))(x)\n",
    "    x = Convolution2D(256, (3,3))(x)\n",
    "    x = Convolution2D(256, (1,1))(x)\n",
    "    x = Convolution2D(256, (3,3))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D(strides=(2,2))(x)\n",
    "\n",
    "    base_model = Model(in_layer, x)\n",
    "    \n",
    "    # Obtain intermediate tensor\n",
    "    intermediate_a = base_model(image_a)\n",
    "    intermediate_b = base_model(image_b)\n",
    "\n",
    "    # Flatten the layer\n",
    "    flatten_a = Flatten()(intermediate_a)\n",
    "    flatten_b = Flatten()(intermediate_b)\n",
    "    \n",
    "    beta         = 1            # Initial beta value\n",
    "    numberOfBits = 256\n",
    "    alpha        = 0.01         # Set to be something small because it prevents the loss function from blowing up.\n",
    "    logger.debug(\"[HashNet Model] beta = {:}, numberOfBits = {:}, alpha = {:}\".format(beta, numberOfBits, alpha))\n",
    "    \n",
    "    def custom_activation(x):\n",
    "        \"\"\"\n",
    "        Our own defined activation function\n",
    "        \"\"\"\n",
    "        global beta\n",
    "        return K.tanh(beta * x)\n",
    "    \n",
    "    class CustomizedLossLayer(Layer):\n",
    "        \"\"\"\n",
    "        Our own defined layer for keeping track of loss function\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, **kwargs):\n",
    "            self.is_placeholder = True\n",
    "            super(CustomizedLossLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def my_loss(self, encoded_a, encoded_b, similarity, weight):\n",
    "            global alpha\n",
    "            x = encoded_a\n",
    "            y = encoded_b\n",
    "            dot_product = K.sum(x * y, axis=-1, keepdims=True)\n",
    "            logger.debug(dot_product)\n",
    "            return K.sum(weight * (K.log(1 + K.exp(alpha * dot_product)) - alpha * similarity * dot_product))\n",
    "\n",
    "        def call(self, inputs):\n",
    "            encoded_a = inputs[0]\n",
    "            encoded_b = inputs[1]\n",
    "            similarity = inputs[2]\n",
    "            weight = inputs[3]\n",
    "            loss = self.my_loss(encoded_a, encoded_b, similarity, weight)\n",
    "            self.add_loss(loss, inputs=inputs)\n",
    "            return K.ones_like(similarity)\n",
    "\n",
    "    hash_layer = Dense(numberOfBits, activation=custom_activation)\n",
    "    encoded_a = hash_layer(flatten_a)\n",
    "    encoded_b = hash_layer(flatten_b)\n",
    "    \n",
    "    # Define a loss layer with 4 inputs\n",
    "    loss = CustomizedLossLayer()([encoded_a, encoded_b, similarity, weight])\n",
    "    \n",
    "    # Define a model that has 4 inputs and outputs loss\n",
    "    model = Model(inputs=[image_a, image_b, similarity, weight], outputs=[loss])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirlab/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-10 18:51:35,381 - root - DEBUG - [HashNet Model] beta = 1, numberOfBits = 256, alpha = 0.01\n",
      "2018-03-10 18:51:35,391 - root - DEBUG - Tensor(\"customized_loss_layer_1/Sum:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(\"2018-03-10[HashNet][Iteration=110].h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(model):\n",
    "    return model.layers[2]\n",
    "base_model = get_base_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(generateOutputCQTList(config['DATA_OUTPUT_DIR'], artist), 'r')\n",
    "db_path = os.path.join(config[\"DATA_OUTPUT_DIR\"], artist + '_db.hdf5')\n",
    "db = h5py.File(db_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-11 05:32:35,997 - root - DEBUG - ==> Generating database for taylorswift_ref1.npy\n",
      "2018-03-11 05:32:36,867 - root - DEBUG - ==> Generating database for taylorswift_ref2.npy\n",
      "2018-03-11 05:32:37,617 - root - DEBUG - ==> Generating database for taylorswift_ref3.npy\n",
      "2018-03-11 05:32:38,635 - root - DEBUG - ==> Generating database for taylorswift_ref4.npy\n",
      "2018-03-11 05:32:39,338 - root - DEBUG - ==> Generating database for taylorswift_ref5.npy\n",
      "2018-03-11 05:32:40,488 - root - DEBUG - ==> Generating database for taylorswift_ref6.npy\n",
      "2018-03-11 05:32:41,379 - root - DEBUG - ==> Generating database for taylorswift_ref7.npy\n",
      "2018-03-11 05:32:42,143 - root - DEBUG - ==> Generating database for taylorswift_ref8.npy\n",
      "2018-03-11 05:32:43,084 - root - DEBUG - ==> Generating database for taylorswift_ref9.npy\n",
      "2018-03-11 05:32:44,127 - root - DEBUG - ==> Generating database for taylorswift_ref10.npy\n",
      "2018-03-11 05:32:45,029 - root - DEBUG - ==> Generating database for taylorswift_ref11.npy\n",
      "2018-03-11 05:32:45,925 - root - DEBUG - ==> Generating database for taylorswift_ref12.npy\n",
      "2018-03-11 05:32:46,761 - root - DEBUG - ==> Generating database for taylorswift_ref13.npy\n",
      "2018-03-11 05:32:47,712 - root - DEBUG - ==> Generating database for taylorswift_ref14.npy\n",
      "2018-03-11 05:32:48,988 - root - DEBUG - ==> Generating database for taylorswift_ref15.npy\n",
      "2018-03-11 05:32:49,867 - root - DEBUG - ==> Generating database for taylorswift_ref16.npy\n",
      "2018-03-11 05:32:50,573 - root - DEBUG - ==> Generating database for taylorswift_ref17.npy\n",
      "2018-03-11 05:32:51,321 - root - DEBUG - ==> Generating database for taylorswift_ref18.npy\n",
      "2018-03-11 05:32:52,195 - root - DEBUG - ==> Generating database for taylorswift_ref19.npy\n",
      "2018-03-11 05:32:53,093 - root - DEBUG - ==> Generating database for taylorswift_ref20.npy\n",
      "2018-03-11 05:32:53,976 - root - DEBUG - ==> Generating database for taylorswift_ref21.npy\n",
      "2018-03-11 05:32:55,062 - root - DEBUG - ==> Generating database for taylorswift_ref22.npy\n",
      "2018-03-11 05:32:55,867 - root - DEBUG - ==> Generating database for taylorswift_ref23.npy\n",
      "2018-03-11 05:32:56,587 - root - DEBUG - ==> Generating database for taylorswift_ref24.npy\n",
      "2018-03-11 05:32:57,391 - root - DEBUG - ==> Generating database for taylorswift_ref25.npy\n",
      "2018-03-11 05:32:58,527 - root - DEBUG - ==> Generating database for taylorswift_ref26.npy\n",
      "2018-03-11 05:32:59,322 - root - DEBUG - ==> Generating database for taylorswift_ref27.npy\n",
      "2018-03-11 05:33:00,060 - root - DEBUG - ==> Generating database for taylorswift_ref28.npy\n",
      "2018-03-11 05:33:00,975 - root - DEBUG - ==> Generating database for taylorswift_ref29.npy\n",
      "2018-03-11 05:33:02,023 - root - DEBUG - ==> Generating database for taylorswift_ref30.npy\n",
      "2018-03-11 05:33:02,822 - root - DEBUG - ==> Generating database for taylorswift_ref31.npy\n",
      "2018-03-11 05:33:03,672 - root - DEBUG - ==> Generating database for taylorswift_ref32.npy\n",
      "2018-03-11 05:33:04,486 - root - DEBUG - ==> Generating database for taylorswift_ref33.npy\n",
      "2018-03-11 05:33:05,337 - root - DEBUG - ==> Generating database for taylorswift_ref34.npy\n",
      "2018-03-11 05:33:06,167 - root - DEBUG - ==> Generating database for taylorswift_ref35.npy\n",
      "2018-03-11 05:33:07,173 - root - DEBUG - ==> Generating database for taylorswift_ref36.npy\n",
      "2018-03-11 05:33:07,949 - root - DEBUG - ==> Generating database for taylorswift_ref37.npy\n",
      "2018-03-11 05:33:09,560 - root - DEBUG - ==> Generating database for taylorswift_ref38.npy\n",
      "2018-03-11 05:33:10,998 - root - DEBUG - ==> Generating database for taylorswift_ref39.npy\n",
      "2018-03-11 05:33:11,815 - root - DEBUG - ==> Generating database for taylorswift_ref40.npy\n",
      "2018-03-11 05:33:12,455 - root - DEBUG - ==> Generating database for taylorswift_ref41.npy\n",
      "2018-03-11 05:33:13,291 - root - DEBUG - ==> Generating database for taylorswift_ref42.npy\n",
      "2018-03-11 05:33:14,488 - root - DEBUG - ==> Generating database for taylorswift_ref43.npy\n",
      "2018-03-11 05:33:15,411 - root - DEBUG - ==> Generating database for taylorswift_ref44.npy\n",
      "2018-03-11 05:33:16,288 - root - DEBUG - ==> Generating database for taylorswift_ref45.npy\n",
      "2018-03-11 05:33:17,582 - root - DEBUG - ==> Generating database for taylorswift_ref46.npy\n",
      "2018-03-11 05:33:18,646 - root - DEBUG - ==> Generating database for taylorswift_ref47.npy\n",
      "2018-03-11 05:33:19,490 - root - DEBUG - ==> Generating database for taylorswift_ref48.npy\n",
      "2018-03-11 05:33:20,221 - root - DEBUG - ==> Generating database for taylorswift_ref49.npy\n",
      "2018-03-11 05:33:21,039 - root - DEBUG - ==> Generating database for taylorswift_ref50.npy\n",
      "2018-03-11 05:33:21,884 - root - DEBUG - ==> Generating database for taylorswift_ref51.npy\n",
      "2018-03-11 05:33:23,320 - root - DEBUG - ==> Generating database for taylorswift_ref52.npy\n",
      "2018-03-11 05:33:24,349 - root - DEBUG - ==> Generating database for taylorswift_ref53.npy\n",
      "2018-03-11 05:33:25,214 - root - DEBUG - ==> Generating database for taylorswift_ref54.npy\n",
      "2018-03-11 05:33:26,296 - root - DEBUG - ==> Generating database for taylorswift_ref55.npy\n",
      "2018-03-11 05:33:26,994 - root - DEBUG - ==> Generating database for taylorswift_ref56.npy\n",
      "2018-03-11 05:33:27,703 - root - DEBUG - ==> Generating database for taylorswift_ref57.npy\n",
      "2018-03-11 05:33:28,430 - root - DEBUG - ==> Generating database for taylorswift_ref58.npy\n",
      "2018-03-11 05:33:29,251 - root - DEBUG - ==> Generating database for taylorswift_ref59.npy\n",
      "2018-03-11 05:33:29,982 - root - DEBUG - ==> Generating database for taylorswift_ref60.npy\n",
      "2018-03-11 05:33:30,835 - root - DEBUG - ==> Generating database for taylorswift_ref61.npy\n",
      "2018-03-11 05:33:31,645 - root - DEBUG - ==> Generating database for taylorswift_ref62.npy\n",
      "2018-03-11 05:33:32,599 - root - DEBUG - ==> Generating database for taylorswift_ref63.npy\n",
      "2018-03-11 05:33:33,466 - root - DEBUG - ==> Generating database for taylorswift_ref64.npy\n",
      "2018-03-11 05:33:34,259 - root - DEBUG - ==> Generating database for taylorswift_ref65.npy\n",
      "2018-03-11 05:33:35,030 - root - DEBUG - ==> Generating database for taylorswift_ref66.npy\n",
      "2018-03-11 05:33:35,854 - root - DEBUG - ==> Generating database for taylorswift_ref67.npy\n",
      "2018-03-11 05:33:36,727 - root - DEBUG - ==> Generating database for taylorswift_ref68.npy\n",
      "2018-03-11 05:33:37,682 - root - DEBUG - ==> Generating database for taylorswift_ref69.npy\n",
      "2018-03-11 05:33:38,555 - root - DEBUG - ==> Generating database for taylorswift_ref70.npy\n",
      "2018-03-11 05:33:39,420 - root - DEBUG - ==> Generating database for taylorswift_ref71.npy\n"
     ]
    }
   ],
   "source": [
    "for line in f:\n",
    "    logger.debug('==> Generating database for %s' % os.path.basename(line)[:-1])\n",
    "    full_path = os.path.join(config[\"DATA_OUTPUT_DIR\"], line[:-1])\n",
    "    Q = np.load(full_path).T\n",
    "        \n",
    "    # Reshape\n",
    "    width, height = Q.shape\n",
    "    Q = Q[:(width - width%76), :].reshape(-1, 1, 76, 121)\n",
    "    \n",
    "    pitch_shift_Qs = np.empty((2 * config['MAX_PITCH_SHIFT'] + 1, ) + Q.shape)\n",
    "    pitch_shift_Qs[0, :, :] = Q\n",
    "    for i in range(1, config['MAX_PITCH_SHIFT'] + 1):\n",
    "        pitch_shift_Qs[i, :, :] = pitch_shift_CQT(Q.T, i).T\n",
    "    for i in range(1, config['MAX_PITCH_SHIFT'] + 1):\n",
    "        pitch_shift_Qs[i + config['MAX_PITCH_SHIFT'], :, :] = pitch_shift_CQT(Q.T, -i).T\n",
    "    \n",
    "    fpseqs = np.array([base_model.predict(pitch_shift_Qs[i]) for i in range(pitch_shift_Qs.shape[0])])\n",
    "\n",
    "    key = os.path.basename(line)[:-1]\n",
    "    db.create_dataset(key, fpseqs.shape, np.bool)\n",
    "    db[key][...] = np.where(fpseqs > 0, True, False)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = os.path.join(config[\"DATA_OUTPUT_DIR\"], artist + '_db.hdf5')\n",
    "db = h5py.File(db_path, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_paths = get_allpaths(artist, os.path.join(config['AUDIO_DIR'], 'Lists/'), file_type='query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing CQT of taylorswift_query1\n",
      "==> Computing CQT of taylorswift_query2\n",
      "==> Computing CQT of taylorswift_query3\n",
      "==> Computing CQT of taylorswift_query4\n",
      "==> Computing CQT of taylorswift_query5\n",
      "==> Computing CQT of taylorswift_query6\n",
      "==> Computing CQT of taylorswift_query7\n",
      "==> Computing CQT of taylorswift_query8\n",
      "==> Computing CQT of taylorswift_query9\n",
      "==> Computing CQT of taylorswift_query10\n",
      "==> Computing CQT of taylorswift_query11\n",
      "==> Computing CQT of taylorswift_query12\n",
      "==> Computing CQT of taylorswift_query13\n",
      "==> Computing CQT of taylorswift_query14\n",
      "==> Computing CQT of taylorswift_query15\n",
      "==> Computing CQT of taylorswift_query16\n",
      "==> Computing CQT of taylorswift_query17\n",
      "==> Computing CQT of taylorswift_query18\n",
      "==> Computing CQT of taylorswift_query19\n",
      "==> Computing CQT of taylorswift_query20\n",
      "==> Computing CQT of taylorswift_query21\n",
      "==> Computing CQT of taylorswift_query22\n",
      "==> Computing CQT of taylorswift_query23\n",
      "==> Computing CQT of taylorswift_query24\n",
      "==> Computing CQT of taylorswift_query25\n",
      "==> Computing CQT of taylorswift_query26\n",
      "==> Computing CQT of taylorswift_query27\n",
      "==> Computing CQT of taylorswift_query28\n",
      "==> Computing CQT of taylorswift_query29\n",
      "==> Computing CQT of taylorswift_query30\n",
      "==> Computing CQT of taylorswift_query31\n",
      "==> Computing CQT of taylorswift_query32\n",
      "==> Computing CQT of taylorswift_query33\n",
      "==> Computing CQT of taylorswift_query34\n",
      "==> Computing CQT of taylorswift_query35\n",
      "==> Computing CQT of taylorswift_query36\n",
      "==> Computing CQT of taylorswift_query37\n",
      "==> Computing CQT of taylorswift_query38\n",
      "==> Computing CQT of taylorswift_query39\n",
      "==> Computing CQT of taylorswift_query40\n",
      "==> Computing CQT of taylorswift_query41\n",
      "==> Computing CQT of taylorswift_query42\n",
      "==> Computing CQT of taylorswift_query43\n",
      "==> Computing CQT of taylorswift_query44\n",
      "==> Computing CQT of taylorswift_query45\n",
      "==> Computing CQT of taylorswift_query46\n",
      "==> Computing CQT of taylorswift_query47\n",
      "==> Computing CQT of taylorswift_query48\n",
      "==> Computing CQT of taylorswift_query49\n",
      "==> Computing CQT of taylorswift_query50\n",
      "==> Computing CQT of taylorswift_query51\n",
      "==> Computing CQT of taylorswift_query52\n",
      "==> Computing CQT of taylorswift_query53\n",
      "==> Computing CQT of taylorswift_query54\n",
      "==> Computing CQT of taylorswift_query55\n",
      "==> Computing CQT of taylorswift_query56\n",
      "==> Computing CQT of taylorswift_query57\n",
      "==> Computing CQT of taylorswift_query58\n",
      "==> Computing CQT of taylorswift_query59\n",
      "==> Computing CQT of taylorswift_query60\n",
      "==> Computing CQT of taylorswift_query61\n",
      "==> Computing CQT of taylorswift_query62\n",
      "==> Computing CQT of taylorswift_query63\n",
      "==> Computing CQT of taylorswift_query64\n",
      "==> Computing CQT of taylorswift_query65\n",
      "==> Computing CQT of taylorswift_query66\n",
      "==> Computing CQT of taylorswift_query67\n",
      "==> Computing CQT of taylorswift_query68\n",
      "==> Computing CQT of taylorswift_query69\n",
      "==> Computing CQT of taylorswift_query70\n",
      "==> Computing CQT of taylorswift_query71\n",
      "==> Computing CQT of taylorswift_query72\n",
      "==> Computing CQT of taylorswift_query73\n",
      "==> Computing CQT of taylorswift_query74\n",
      "==> Computing CQT of taylorswift_query75\n",
      "==> Computing CQT of taylorswift_query76\n",
      "==> Computing CQT of taylorswift_query77\n",
      "==> Computing CQT of taylorswift_query78\n",
      "==> Computing CQT of taylorswift_query79\n",
      "==> Computing CQT of taylorswift_query80\n",
      "==> Computing CQT of taylorswift_query81\n",
      "==> Computing CQT of taylorswift_query82\n",
      "==> Computing CQT of taylorswift_query83\n",
      "==> Computing CQT of taylorswift_query84\n",
      "==> Computing CQT of taylorswift_query85\n",
      "==> Computing CQT of taylorswift_query86\n",
      "==> Computing CQT of taylorswift_query87\n",
      "==> Computing CQT of taylorswift_query88\n",
      "==> Computing CQT of taylorswift_query89\n",
      "==> Computing CQT of taylorswift_query90\n",
      "==> Computing CQT of taylorswift_query91\n",
      "==> Computing CQT of taylorswift_query92\n",
      "==> Computing CQT of taylorswift_query93\n",
      "==> Computing CQT of taylorswift_query94\n",
      "==> Computing CQT of taylorswift_query95\n",
      "==> Computing CQT of taylorswift_query96\n",
      "==> Computing CQT of taylorswift_query97\n",
      "==> Computing CQT of taylorswift_query98\n",
      "==> Computing CQT of taylorswift_query99\n",
      "==> Computing CQT of taylorswift_query100\n"
     ]
    }
   ],
   "source": [
    "def get_query_shape():\n",
    "    '''\n",
    "        returns the shape of query file in (width, height)\n",
    "    '''\n",
    "    assert len(query_paths) > 0\n",
    "    cur_file = query_paths[0]\n",
    "    y, sr = librosa.load(config[\"AUDIO_DIR\"] + cur_file + '.wav')\n",
    "    Q = librosa.cqt(y, sr=sr, fmin=130.81, n_bins=121, bins_per_octave=24, hop_length=96)\n",
    "    logQ = preprocess(Q, 3)\n",
    "    return logQ.T.shape\n",
    "\n",
    "query_shape = get_query_shape()\n",
    "queries = np.empty((len(query_paths), ) + query_shape)\n",
    "\n",
    "for i in range(len(query_paths)):\n",
    "    cur_file = query_paths[i]\n",
    "    print('==> Computing CQT of %s'%cur_file)\n",
    "    y, sr = librosa.load(config[\"AUDIO_DIR\"] + cur_file + '.wav')\n",
    "    Q = librosa.cqt(y, sr=sr, fmin=130.81, n_bins=121, bins_per_octave=24, hop_length=96)\n",
    "    logQ = preprocess(Q, 3)\n",
    "    queries[i, :, :] = logQ.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "for query in queries:\n",
    "    width, height = query.shape\n",
    "    query = query[:(width - width%76), :].reshape(-1, 1, 76, 121)\n",
    "    output = np.where(base_model.predict(query) > 0, True, False)\n",
    "    q.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = list(db.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = get_querytoref(artist, os.path.join(config['AUDIO_DIR'], 'Lists/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculateMRR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-9c9d08972586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateMRR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'calculateMRR' is not defined"
     ]
    }
   ],
   "source": [
    "mrr = calculateMRR(querys, refs, ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
